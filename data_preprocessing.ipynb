{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ofir-final-project-preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5jjCCeja7ObFWfA0AYyKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ofir408/ml-feature-selection/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ofir Ben Shoham"
      ],
      "metadata": {
        "id": "EzbUP2cKFX4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This nootbook is part of the code of the final project. \n",
        "\n",
        "Here I do the required preprocessing on the 20 datasets"
      ],
      "metadata": {
        "id": "720ahlNmFcaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "ke2R9mWjFoKg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "f3jy7x0iFTz0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c5iz57mFqdE",
        "outputId": "76eba10a-2213-43c9-c208-cca995a17507"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "rJFcEXZWUz_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import Normalizer, PowerTransformer\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "def preprocess(X, y):\n",
        "  prep_df = pd.DataFrame(X, columns=[\"Feature\" + str(x) for x in range(X.shape[1])])\n",
        "\n",
        "  ct = ColumnTransformer(\n",
        "    [\n",
        "        (\"simpleImputer\", SimpleImputer(missing_values=np.nan, strategy='mean'), prep_df.columns),\n",
        "        (\"varianceThreshold\", VarianceThreshold(), prep_df.columns),\n",
        "        (\"normalizer\", PowerTransformer(), prep_df.columns)\n",
        "\n",
        "    ])\n",
        "  X = ct.fit_transform(prep_df)\n",
        "  prep_df['y'] = y\n",
        "\n",
        "  preprocess_df = pd.DataFrame(X, columns=[\"Feature\" + str(x) for x in range(X.shape[1])])\n",
        "  preprocess_df['y'] = y\n",
        "  return preprocess_df\n",
        "\n"
      ],
      "metadata": {
        "id": "zKzAFyzuU1AX"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### scikit-feature datasets preprocessing"
      ],
      "metadata": {
        "id": "k6BnjUJLwhL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ds_name in ['colon', 'Yale', 'GLIOMA', 'arcene', 'Carcinom']:\n",
        "  mat = scipy.io.loadmat(f'/content/gdrive/MyDrive/ml-bgu/datasets/scikit-feature/{ds_name}.mat')\n",
        "  X = mat['X']\n",
        "  y = mat['Y']\n",
        "  final_df = preprocess(X, y)\n",
        "  final_df.to_csv(f'/content/gdrive/MyDrive/ml-bgu/datasets_after_preprocessing/{ds_name}.csv')\n"
      ],
      "metadata": {
        "id": "w-ZjQqDxhWHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datamicroarray datasets preprocessing\n"
      ],
      "metadata": {
        "id": "C4YJTHxFwl0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyreadr\n",
        "dir_path = '/content/gdrive/MyDrive/ml-bgu/datasets/Datamicroarray/csv/'\n",
        "\n",
        "for ds_name in ['alon', 'christensen', 'khan', 'sorlie', 'west']:\n",
        "  inputs_file_path = f'{dir_path}/{ds_name}/{ds_name}_inputs.csv'\n",
        "  outputs_file_path = f'{dir_path}/{ds_name}/{ds_name}_outputs.csv'\n",
        "  inputs_df = pd.read_csv(inputs_file_path, header=None)\n",
        "  inputs_df.columns = [str(x) for x in inputs_df.columns]\n",
        "  outputs_df = pd.read_csv(outputs_file_path, header=None)\n",
        "  outputs_df.columns = ['y']\n",
        "\n",
        "  final_df = preprocess(inputs_df.to_numpy(), outputs_df.to_numpy())\n",
        "  final_df.to_csv(f'/content/gdrive/MyDrive/ml-bgu/datasets_after_preprocessing/{ds_name}.csv')\n"
      ],
      "metadata": {
        "id": "cFtCt_3D1e9E"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Misc datasets preprocessing"
      ],
      "metadata": {
        "id": "EIdcYc0ND1do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import arff\n",
        "dir_path = '/content/gdrive/MyDrive/ml-bgu/datasets/Misc'\n",
        "\n",
        "for ds_name in ['GDS3610', 'GDS6063']:\n",
        "  df = pd.read_csv(f'{dir_path}/{ds_name}.csv')\n",
        "  final_df = preprocess(df.to_numpy(), df['Class'].to_numpy())\n",
        "  final_df.to_csv(f'/content/gdrive/MyDrive/ml-bgu/datasets_after_preprocessing/{ds_name}.csv')\n"
      ],
      "metadata": {
        "id": "hgxtBE8iD9an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "for ds_name in ['journal.pone.0246039.s002', 'journal.pone.0246039.s005',\n",
        "                'pone.0246039.s001']:\n",
        "  df = pd.read_csv(f'{dir_path}/{ds_name}.csv')\n",
        "  if 'samples' in df.columns:\n",
        "    df.drop(columns=['samples'], inplace=True)\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  class_column = le.fit_transform(df['Response'])\n",
        "  final_df = preprocess(df.drop(columns=['Response']).to_numpy(), class_column)\n",
        "  final_df.to_csv(f'/content/gdrive/MyDrive/ml-bgu/datasets_after_preprocessing/{ds_name}.csv')\n"
      ],
      "metadata": {
        "id": "U_G6LyKkTfN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mAML datasets preprocessing"
      ],
      "metadata": {
        "id": "jqpJExSprvZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/gdrive/MyDrive/ml-bgu/datasets/mAML_benchmark_datasets'\n",
        "\n",
        "for ds_name in ['Montassier2016_Bacteremia', 'Qin2012_Diabetes',\n",
        "                'Ravel2011_Vaginal', 'Wu2011_Diet', 'Costello2009_Subject.7']:\n",
        "  print(f'ds_name={ds_name}')\n",
        "  inputs_df = pd.read_csv(f'{dir_path}/{ds_name}.csv')\n",
        "  output_df = pd.read_csv(f'{dir_path}/{ds_name}.mf.csv')\n",
        "  df = inputs_df.join(output_df, lsuffix='i')\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  class_column = le.fit_transform(df['label'])\n",
        "  final_df = preprocess(df.drop(columns=['#SampleID', '#SampleIDi', 'label']).to_numpy(), class_column)\n",
        "  final_df.to_csv(f'/content/gdrive/MyDrive/ml-bgu/datasets_after_preprocessing/{ds_name}.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mShf_FTpxKxR",
        "outputId": "cd6c88c3-00ad-4e01-f8a6-cea092218ec3"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ds_name=Montassier2016_Bacteremia\n",
            "ds_name=Qin2012_Diabetes\n",
            "ds_name=Ravel2011_Vaginal\n",
            "ds_name=Wu2011_Diet\n",
            "ds_name=Costello2009_Subject.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### validation that everything was good"
      ],
      "metadata": {
        "id": "epSxDh4zvo_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/ml-bgu/datasets_after_preprocessing/Misc/GDS3610.csv')\n",
        "X = df.drop(columns=['y'])\n",
        "y = df['y']\n",
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(gamma='auto')\n",
        "cross_val_score(clf, X, y.ravel(), cv=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrcmCOHJvrKL",
        "outputId": "640d8a32-3a47-469b-c4a3-060f8bec8ab2"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9       , 0.88888889, 0.88888889])"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    }
  ]
}